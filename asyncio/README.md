# Asyncio vs Multithreading vs Multiprocessing

| Concept               | What‚Äôs Really Happening                                                                                                                              | Key Rule                                                                                                                      |
| --------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **`asyncio`**         | A _single-threaded_, cooperative multitasking system. One event loop, many coroutines. Each coroutine _yields_ with `await`, allowing others to run. | Don‚Äôt block the loop! Only use `await`-based or async-friendly functions (e.g., `await asyncio.sleep()`, not `time.sleep()`). |
| **`threading`**       | Multiple OS-level threads, each with its own GIL-managed execution context.                                                                          | Each thread can have its _own event loop_, but only one loop can run per thread.                                              |
| **`multiprocessing`** | Spawns _new Python interpreters_ (separate processes) with their own memory, GIL, and threads.                                                       | Processes communicate via IPC (e.g. `Queue`, `Pipe`, `Value`, shared memory). Perfect for CPU-bound work.                     |

```
[asyncio] single loop, single thread
‚îú‚îÄ task 1 ‚îÄ‚ñ∂ await
‚îú‚îÄ task 2 ‚îÄ‚ñ∂ await
‚îî‚îÄ task 3 ‚îÄ‚ñ∂ await
‚Ü≥ yields to scheduler, all on same core

[threading]
‚îú‚îÄ thread 1: maybe runs asyncio loop
‚îú‚îÄ thread 2: maybe blocking I/O
‚îî‚îÄ thread 3: background worker
‚Ü≥ All share same process memory, GIL-enforced switching

[multiprocessing]
‚îú‚îÄ process 1: its own memory, GIL, and threads
‚îú‚îÄ process 2: independent interpreter
‚îî‚îÄ process 3: communicates via IPC (Queue, Pipe)
‚Ü≥ True parallel execution on separate cores
```

# What to choose when

| Task Type                                              | Use This              | Why                                                                |
| ------------------------------------------------------ | --------------------- | ------------------------------------------------------------------ |
| I/O bound (HTTP calls, DB queries, waiting on sockets) | **`asyncio`**         | Non-blocking, single-threaded concurrency                          |
| CPU bound (math, encryption, parsing)                  | **`multiprocessing`** | True parallelism across cores                                      |
| Mixed / legacy blocking code                           | **`threading`**       | Integrates blocking code with async via `to_thread()` or executors |

# üß† Asyncio ‚ÄúWhere to Await vs Not‚Äù Cheat Sheet

| Situation / Expression                                 | Should you `await`?                               | Notes / Memory Hook                                                                           |
| ------------------------------------------------------ | ------------------------------------------------- | --------------------------------------------------------------------------------------------- |
| `async def foo()` ‚Üí `foo()`                            | ‚úÖ Yes (or schedule via create_task)              | Calling an `async def` gives a coroutine object; you must await it to run it (or schedule it) |
| `asyncio.sleep(...)`                                   | ‚úÖ Yes                                            | Sleep is async; await it to pause this coroutine without blocking the loop                    |
| `await asyncio.to_thread(blocking_fn, ...)`            | ‚úÖ Yes                                            | Wrapping sync/blocking code in a thread; await the result                                     |
| `loop.run_in_executor(pool, blocking_fn, ...)`         | ‚úÖ Yes                                            | Same idea as `to_thread` but with explicit executor                                           |
| `asyncio.create_task(coro())` ‚Üí assigned to a variable | ‚ùå Not immediately                                | Scheduling for concurrency; you can await later if you want the result                        |
| `await asyncio.create_task(coro())`                    | ‚ùå Usually                                        | Redundant ‚Äî you scheduled it just to immediately wait, same as `await coro()`                 |
| `asyncio.gather(coro1(), coro2(), ...)`                | ‚úÖ Yes                                            | Waits for all coroutines concurrently; returns results in order                               |
| Fire-and-forget background task                        | ‚ùå Not now                                        | `asyncio.create_task(coro())` without awaiting ‚Üí runs in background; track if needed          |
| `asyncio.as_completed([...])`                          | ‚úÖ Inside a loop                                  | `await` each future as it finishes to process results incrementally                           |
| Sync function that **doesn‚Äôt block**                   | ‚ùå No                                             | Just call normally; no need to wrap or await                                                  |
| Sync function that **blocks** (e.g., `time.sleep`)     | ‚úÖ Wrap in `to_thread` or `run_in_executor` first | Never `await` a pure blocking sync function ‚Äî it will freeze the loop                         |

# Event Loop Pseudo Code

- run ready ‚Üí run timers ‚Üí run I/O events ‚Üí repeat

```python
while True:
    run_ready_callbacks()
    run_due_timers()
    poll_io_events()
    add ready I/O callbacks to READY queue
```

- ‚ÄúNext event loop tick‚Äù = the next moment the event loop gets CPU time after your coroutine yields or finishes the current line of code = **next iteration of the loop**

# More on asyncio

- Calling an `async def` does NOT run its body. It only creates a coroutine object.

```python
async def check_status(rtn_prd):
    return await loop.run_in_executor(
        None,
        lambda: file_download_status(
            rtn_prd=rtn_prd,
        ),
    )

tasks = [check_status(p) for p in request.rtn_prd] # This only creates coroutine objects.
# It does NOT run:

# any code inside check_status

# definitely does NOT run await loop.run_in_executor

# Nothing inside executes until the event loop actually schedules them.
results = await asyncio.gather(*tasks) # Parallel "execution"
```

### Why doesn‚Äôt `check_status(p)` immediately call `await`?

Because:

- `check_status` is defined using `async def`

- Calling an `async def` returns a coroutine object

- A coroutine object is ‚Äúpaused at the first line‚Äù

- It does not start executing until you do one of the following:

  - `await check_status(p)`

  - `asyncio.create_task(check_status(p))`

  - `asyncio.gather(check_status(p))`

  - the event loop resumes it for any reason

### When do they actually run?

When you do:

```python
results = await asyncio.gather(*tasks)
```

Now here's what happens:

1. gather takes each coroutine

2. Schedules all of them in the event loop immediately

3. Starts running them concurrently

4. Each coroutine enters the body of check_status

5. They finally hit:

```python
await loop.run_in_executor(...)
```

**That is the FIRST moment any of the executor code actually executes.**

‚úîÔ∏è So the flow in above case is:

1. Define async function
   ```python
   async def check_status(...): # doesn't run anything
   ```
2. Call the async function ‚Üí creates coroutine object

   ```python
   coro = check_status(p) # still doesn't run anything
   ```

3. Event loop runs them through gather

   ```python
   await asyncio.gather(coro1, coro2, coro3)
   ```

4. Now the body executes

   ```python
   return await loop.run_in_executor(...)
   ```

5. The run_in_executor submits work to the threadpool

   - This is scheduled immediately in the threadpool

   - But the coroutine pauses waiting for the thread result

   - Meanwhile, other coroutines run ‚Äî giving you concurrency

## [Parallel v Sequential Execution in asyncio](./parallel-v-sequential.py)

### **1. `await`**

üëâ _Wait for a coroutine/future to finish. Makes execution SEQUENTIAL at that point._

---

### **2. `asyncio.gather(*coros)`**

üëâ _Run multiple coroutines CONCURRENTLY and wait for all of them._

---

### **3. `asyncio.create_task(coro)`**

üëâ _Schedule a coroutine to run in the background (fire-and-forget). Runs CONCURRENTLY._

---

### **4. `asyncio.to_thread(func, *args)`**

üëâ _Run a blocking function in a thread. Returns a coroutine you must await. Runs CONCURRENTLY across threads._

---

### **5. `loop.run_in_executor(executor, func, *args)`**

üëâ _Lower-level version of `to_thread`. Runs blocking code in threads or processes._

---

### **6. `asyncio.sleep(x)`**

üëâ _Yield to event loop for x seconds. Doesn‚Äôt block the loop._

---

### **7. `asyncio.wait_for(coro, timeout)`**

üëâ _Run a coroutine with timeout enforcement._

---

### **8. `asyncio.Semaphore(n)`**

üëâ _Limit concurrency ‚Äî useful when hitting APIs or databases._

---

## ‚ö° When is execution **parallel**, **concurrent**, or **sequential**?

### ‚úîÔ∏è **Sequential**

You get sequential behavior when you do:

#### **Using `await` inside a loop**

```python
for p in items:
    result = await check(p)   # waits one-by-one
```

#### **Calling blocking code directly**

```python
result = some_heavy_cpu_func()   # blocks everything
```

---

## ‚úîÔ∏è **Concurrent (async coroutines)**

Coroutines run _overlapping in time_ (not literally parallel CPU threads unless using threads or processes).

### **Using `asyncio.gather`**

```python
await asyncio.gather(check(a), check(b), check(c))
```

### **Using `asyncio.create_task`**

```python
task = asyncio.create_task(check(x))
# (you don't await ‚Äî it runs concurrently)
```

---

## ‚úîÔ∏è **Parallel (actual threads or processes)**

Happens when you offload blocking work.

### **Using `asyncio.to_thread`**

```python
await asyncio.to_thread(blocking_func)
```

### **Using `run_in_executor`**

```python
await loop.run_in_executor(None, blocking_func)
```

### **Using `ProcessPoolExecutor`**

```python
await loop.run_in_executor(process_pool, cpu_heavy_func)
```

---

# üß† TL;DR

- **`await` inside a loop ‚Üí sequential**
- **`gather` ‚Üí concurrent**
- **`create_task` ‚Üí fire-and-forget concurrent**
- **`to_thread` / `run_in_executor` ‚Üí parallel threads**
- **CPU work ‚Üí use processes for true parallelism**
- **Blocking sync code ‚Üí stick it in `to_thread`**

# JS vs Python Comparison

## üß† First: The JS World

### **JavaScript has two named queues:**

| JS Queue            | Meaning                                            |
| ------------------- | -------------------------------------------------- |
| **Microtask queue** | Promises, `async/await`, `.then()` callbacks       |
| **Macrotask queue** | `setTimeout`, `setInterval`, I/O events, UI events |

Event loop order: **Run microtask queue ‚Üí then macrotask ‚Üí repeat**

---

## üêç Python World: Similar concepts, **different names**

Python (asyncio) event loop has **the same conceptual split**, but they are NOT called micro/macro tasks.

Instead, Python has these ‚Äúnamed queues / structures‚Äù:

---

# üìå **1. Ready Queue** _(‚Äúcallbacks ready to run now‚Äù)_

This is the closest to **JS microtask queue**.

Contains:

- Tasks that just became ready after an `await`
- Callbacks scheduled via `loop.call_soon`
- Callbacks from completed Futures
- Tasks resumed from I/O events

Think of `ready` as:

> ‚ÄúEverything the loop should run immediately, before it does anything else.‚Äù

---

# üìå **2. Scheduled Calls Queue (Timer Queue)**

This is a **min-heap (priority queue)** of timed callbacks.

Equivalent to **JS macrotask setTimeout**.

Contains:

- `loop.call_later(delay, callback)`
- `loop.call_at(timestamp, callback)`
- Sleep wakeups (`await asyncio.sleep(...)`)
- Timeout events

This queue determines **future callbacks** based on time.

---

# üìå **3. I/O Selector (I/O event queue)**

This is the **epoll / kqueue / I/O multiplexer** layer.

Contains:

- Socket read readiness
- Socket write readiness
- Pipe, file-descriptor, network events

Equivalent to:

> ‚Äúmacrotasks triggered by I/O events‚Äù in JS.

When an I/O event is ready, the event loop puts the corresponding task into the **Ready Queue**.

---

# üìå **4. Executor Thread/Process Callback Queue**

When you use:

- `asyncio.to_thread`
- `loop.run_in_executor`
- ProcessPoolExecutor

The result of the thread/process comes back through a special callback:

> ‚ÄúExecutor result ready ‚Üí put a callback into **Ready Queue**.‚Äù

JS equivalent:

- Worker threads returning results via event loop

---

# üìå **5. Task Objects internally manage their own state**

While not a queue, each `Task` individually manages:

- PENDING
- RUNNING
- SCHEDULED
- FINISHED
- CANCELLED

A Task becomes runnable and enters the **Ready Queue** whenever its awaited thing completes.

---

# üéØ Summary Table (JS vs Python Queues)

| Concept                            | JS Name                | Python Name                            | Notes                              |
| ---------------------------------- | ---------------------- | -------------------------------------- | ---------------------------------- |
| Tasks that must run ASAP           | **Microtask Queue**    | **Ready Queue**                        | Includes resumed coroutine steps   |
| Delayed callbacks                  | **Macrotask (timers)** | **Scheduled Calls Queue (timer heap)** | Same concept                       |
| Network / file I/O                 | **Macrotask (I/O)**    | **I/O selector / poller**              | When ready ‚Üí goes into Ready Queue |
| Background threads/process results | Worker callbacks       | Executor callback queue ‚Üí Ready Queue  |                                    |
| Promises                           | Promise microtasks     | Future callbacks ‚Üí Ready Queue         |                                    |

---

# üìå **Python event loop flow (simplified)**

```python
while True:
    run_ready_callbacks()
        ‚Üì
        If one of these tasks hits `await`,
        it is SUSPENDED and removed from ready queue.
        Loop DOES NOT immediately jump to next steps.
        It simply finishes processing current ready callback,
        then proceeds:

    run_due_timers()
        - check if any timer expired (e.g. sleep finished)
        - if yes ‚Üí put those callbacks into READY queue

    poll_io_events()
        - check sockets, file descriptors
        - if ready ‚Üí put those callbacks into READY queue

    (loop back)

```

## Analogy

```python
Task A running...
Task A hits await something
    ‚Üí Task A pauses
    ‚Üí Task A is moved to "waiting list"
    ‚Üí Event loop takes control back
Event loop:
    - resumes Task B from ready queue
    - resumes Task C
    - checks timers
    - checks I/O sockets
    - when "something" is done, task A is moved back to ready queue
Event loop picks Task A ‚Üí resumes where it left off
```

JS:

```
run microtasks ‚Üí run macrotasks ‚Üí repeat
```

Python:

```
run ready ‚Üí run timers ‚Üí run I/O events ‚Üí repeat
```

## What does `await`ing something means?

```
await something
‚Üì
move coroutine to waiting state
‚Üì
event loop runs other ready tasks, timers, I/O
‚Üì
when awaited future is done, put coroutine back into READY queue
‚Üì
resume it at next event loop tick

```

---

# üß® Why Python doesn't have explicit micro/macro task vocabulary?

Because:

- Python exposes the **coroutines**, not the queue semantics
- You control scheduling via `await`, `create_task`, and timers
- The loop‚Äôs queues exist internally, not conceptually for devs

But the behavior is nearly identical.

---

| ‚ÄúQueue Type‚Äù                   | JS Name           | Python Equivalent                    | When It's Used                                           |
| ------------------------------ | ----------------- | ------------------------------------ | -------------------------------------------------------- |
| **Immediate / next tick work** | Microtask queue   | **Ready queue**                      | Awaited coroutines resuming, FUTURE callbacks, call_soon |
| **Timed work**                 | Macrotask (timer) | **Scheduled calls heap**             | sleep, call_later, timeouts                              |
| **I/O work**                   | Macrotask (I/O)   | **I/O selector / poller**            | Sockets, network events                                  |
| **Thread / process results**   | Worker callback   | **Executor callbacks ‚Üí Ready queue** | to_thread, run_in_executor                               |

---
